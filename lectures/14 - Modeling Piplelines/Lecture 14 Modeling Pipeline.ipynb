{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set defaults\n",
    "plt.style.use('seaborn-white')   # seaborn custom plot style\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))   # set default size/resolution\n",
    "plt.rc('font', size=12)   # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling pipeline\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The steps of the modeling pipeline\n",
    "\n",
    "1. Create features to best reflect the meaning behind data\n",
    "2. Create model appropriate to capture relationships between features\n",
    "    - e.g. linear, non-linear\n",
    "3. Select a loss function and fit the model (determine $\\hat{\\theta}$).\n",
    "4. Evaluate model (e.g. using RMSE)\n",
    "\n",
    "After these steps, use the model for prediction and/or inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Software development and the modeling pipeline \n",
    "\n",
    "* Each step may contain complicated transformations and logic\n",
    "* The pipeline above represents a single attempt at a model\n",
    "    - May have thousands of feature/model/paramater combinations to choose from!\n",
    "    - Remember the Data Science Life Cycle!\n",
    "* ML pipelines: [the high interest credit card of technical debt](https://ai.google/research/pubs/pub43146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features and Models using `Scikit Learn`\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* Scikit-Learn implements many common steps in the feature/model creation pipeline.\n",
    "* It interfaces with `numpy` arrays, *not* Pandas dataframes :(\n",
    "    - Some work required keeping track of columns in scikit\n",
    "    \n",
    "    \n",
    "<img src=\"imgs/sklearn.png\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn feature transformers\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "<img src=\"imgs/feature_part.png\" width=\"50%\">\n",
    "\n",
    "<img src=\"imgs/image_1.png\" width=\"100%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn (linear) models\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "<img src=\"imgs/model_part.png\" width=\"50%\">\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_2.png\" width=\"100%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-Learn Transformer Classes\n",
    "\n",
    "* Transformers process data and output features (transformed data).\n",
    "    - Input data should be a (multi-column) Numpy Array (`sklearn` coerces a dataframe using `.values`).\n",
    "    - Output data is also a Numpy Array.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `binar = Binarizer(thresh)` | 'set x=0 if x < thresh, else 1'|\n",
    "|Transform data in a dataset | `feat = binar.transform(data)` | Binarize all columns in `data`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the transformer and use it in the dataset\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi = Binarizer(threshold = 20)                     # initialize with the parameter\n",
    "binarized = bi.transform(tips[['total_bill']])     # called transform on a data \n",
    "binarized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if works, by hand\n",
    "# plot binarized data\n",
    "# \n",
    "(\n",
    "    pd.concat([tips.total_bill, pd.DataFrame(binarized, columns=['binarized'])], axis=1)\n",
    "    .sort_values('total_bill')\n",
    "    .plot(x='total_bill', y='binarized')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some transformer classes require fitting\n",
    "\n",
    "* Transformation logic often requires some knowledge of the dataset before transforming.\n",
    "    - z-score: z = (x-μ)/σ, where x is the raw score, μ is the population mean, and σ is the population standard deviation.\n",
    "* These transformers must be *fit* to the data before use.\n",
    "* Typical usage: fit transformer on a sample; use that fit transformer to transform future data.\n",
    "\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-scale the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(data)` | compute the mean and std-dev of `data`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(newdata)` | z-scale `newdata` with mean/stdev of `data`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>size</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>2</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.68</td>\n",
       "      <td>2</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24.59</td>\n",
       "      <td>4</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  size   tip\n",
       "0       16.99     2  1.01\n",
       "1       10.34     3  1.66\n",
       "2       21.01     3  3.50\n",
       "3       23.68     2  3.31\n",
       "4       24.59     4  3.61"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "quantcols = ['total_bill', 'size', 'tip']\n",
    "tips[quantcols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c1b9e8b546dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This doesn't work!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstdscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquantcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mCopy\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \"\"\"\n\u001b[0;32m--> 753\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scale_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "# This doesn't work!\n",
    "stdscaler.transform(tips[quantcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdscaler.fit(tips[quantcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.78594262,  2.56967213,  2.99827869])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attributes\n",
    "stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78.92813149,  0.9008835 ,  1.90660851])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attributes \n",
    "stdscaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31471131, -0.60019263, -1.43994695],\n",
       "       [-1.06323531,  0.45338292, -0.96920534],\n",
       "       [ 0.1377799 ,  0.45338292,  0.36335554],\n",
       "       [ 0.4383151 , -0.60019263,  0.22575414],\n",
       "       [ 0.5407447 ,  1.50695847,  0.4430195 ],\n",
       "       [ 0.61953671,  1.50695847,  1.23965916],\n",
       "       [-1.23995452, -0.60019263, -0.72297126],\n",
       "       [ 0.79850711,  1.50695847,  0.08815275],\n",
       "       [-0.53420331, -0.60019263, -0.75193998],\n",
       "       [-0.56346891, -0.60019263,  0.16781671]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z-scaled data\n",
    "stdscaler.transform(tips[quantcols])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-Learn Model Classes\n",
    "\n",
    "`Sklearn` model classes (estimators) behave like transformers, but use outcomes (target variables, dependent variables that you train your model on) to fit and evaluate.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize model parameters| `lr = LinearRegression()` | Create (empty) linear regression model|\n",
    "|Fit the model to the data | `lr.fit(data, outcomes)` | Determines regression coefficients|\n",
    "|Use model for prediction |`lr.predict(newdata)`| Use regression line make predictions|\n",
    "|Evaluate the model| `lr.score(data, outcomes)` | Calculate the $R^2$ of the LR model|\n",
    "|Access model attributes| `lr.coef_` | Access the regression coefficients|\n",
    "\n",
    "*Note:* Once `fit`, estimators are just transformers (`predict` <-> `transform`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(tips[['total_bill', 'size']], tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.62933992, 2.20539403, 3.19464533, 3.24959215, 3.71915687,\n",
       "       3.78405621, 1.86723629, 3.93147041, 2.44854892, 2.42444345])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can predict with it\n",
    "# we have first 10 predicted tips\n",
    "lr.predict(tips[['total_bill', 'size']])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09271334, 0.19259779])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regression coefficients, why 2 slopes?\n",
    "# ax + by + z\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689447408125027"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building models with transformers and estimators\n",
    "\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "1. Define your transformations; models.\n",
    "1. Transform input data to features.\n",
    "1. Use (transformed) features to fit model.\n",
    "1. Predict outcomes from features using fit model.\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just categoricals\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "tips_cat = ['sex', 'smoker', 'day', 'time']\n",
    "regdata = tips[tips_cat]\n",
    "regdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()  # create\n",
    "ohe.fit(regdata)       # fit to data\n",
    "ohe.categories_        # you can look into created categories ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are they columns? Will be passed automatically to the model\n",
    "features = ohe.transform(regdata)#.toarray()  # why toarray()? to avoid sparse matrix!\n",
    "features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "# this is a bad model because of multicollinearity\n",
    "# which variables should be dropped?\n",
    "lr.fit(features, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher dim. plane of best fit in 10 dim  (slopes)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE: terrible model! (why?)\n",
    "np.sqrt(np.mean((preds - tips.tip.values)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predictions to original data\n",
    "tips.assign(preds=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting it together: Scikit-Learn Pipelines\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Put together transformers and models using `sklearn.Pipeline`.\n",
    "* Create a pipeline: `pl = Pipeline([feat_trans, mdl])`\n",
    "* Fit *all* the transformer(s)/model(s) in the pipeline using `pl.fit(data, target)`\n",
    "* Predict from *raw* input data through the pipeline using `pl.predict`.\n",
    "* Note: a fit pipeline is also a transformer!\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a list of feature trans. and models, in sequence.\n",
    "# does all fitting and transforming\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines are lists of steps: each is a transformation/estimator\n",
    "# each transformation is a tuple: the 'name' for the step name, and the transformer/estimator object.\n",
    "pl = Pipeline([\n",
    "    ('one-hot', OneHotEncoder()),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(regdata, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the 'steps' of the pipeline using .named_steps\n",
    "# gives a dictionary\n",
    "# key: name you gave\n",
    "# values: fit pipleline objects\n",
    "pl.named_steps['one-hot'].transform(regdata).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(regdata)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 -- still terrible!\n",
    "pl.score(regdata, tips.tip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (Realistic) Sklearn Pipelines\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* `ColumnTransformer` is a new (experimental) Pipeline object \n",
    "* Transforms using multiple transformers, each on different columns.\n",
    "* `ColumnTransformer` performs the transformations and concatenates the output (axis=1).\n",
    "\n",
    "<img src=\"imgs/image_3.png\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split data up into quant. and cat. features\n",
    "# 2. z-scale for quant features\n",
    "# 3. One-hot encode for cat. features\n",
    "# 4. Two pipelines\n",
    "# 5. Use column transformer to put everything back\n",
    "# 6. Apply the model => predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.drop(['tip', 'total_bill', 'size'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns and associated transformers\n",
    "num_feat = ['total_bill', 'size']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())   # z-scale\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_feat = ['sex', 'smoker', 'day', 'time']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('intenc', pp.OrdinalEncoder()),   # converts to int\n",
    "    ('onehot', pp.OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(transformers=[('num', num_transformer, num_feat), ('cat', cat_transformer, cat_feat)])\n",
    "\n",
    "pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips.drop('tip', axis=1), tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pl.predict(tips.drop('tip', axis=1))\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((preds - tips.tip)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.score(tips.drop('tip', axis=1), tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['preprocessor']#.transform(tips.drop('tip', axis=1))#.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the fit model\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_4.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a model\n",
    "\n",
    "* Given a fit regressor on dataset, calculate e.g. the root-mean-square error.\n",
    "* If the error is low, do you think it's a good model?\n",
    "    - It fits the given *data* well, but is it a good model? (Is the sample representative?)\n",
    "    - Will it give good predictions on similar, unknown, data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fundamental Concepts of the quality of a 'fit model'\n",
    "\n",
    "* **Bias**: the expected deviation between the predicted value and true value\n",
    "* **Variance**: \n",
    "    - **Observation Variance**: the variability of the random noise in the process we are trying to model. \n",
    "    - **Estimated Model Variance**: the variability in the predicted value across different datasets. (Does the model generalize?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Quality: Bias and Variance\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* The red bulls-eye: the true behavior of DGP\n",
    "* Each dart: a specific function that models/predicts the DGP\n",
    "* The model parameters $\\theta$ select these functions.\n",
    "* Credit: Scott Fortmann-Roe\n",
    "    \n",
    "<img src=\"imgs/image_5.png\" width=\"100%\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a linear model\n",
    "\n",
    "Given a dataset on which to fit the regression coefficients:\n",
    "1. Calculate the RMSE to test for bias.\n",
    "2. To test for variance, bootstrap estimate the regression coefficients:\n",
    "    - sample the data.\n",
    "    - For each sample, calculate the linear predictor.\n",
    "    - For each input feature, calculate the CI for the distribution of predictions.\n",
    "    - Large \"prediction intervals\" imply the model is susceptible to noise (e.g. outliers)\n",
    "    \n",
    "Still, this relies on a \"representative sample\" for generalization to new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips, x='total_bill', y='tip');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a (general) model\n",
    "\n",
    "* Given a fit (non-linear) model, there are three possibilities for quality:\n",
    "    - The model doesn't fit the given data well (high bias; underfit)\n",
    "    - Does it reflect the process of interest? (good fit; robust)\n",
    "    - Does it just fit the data (noise and all)? (high variance; overfit)\n",
    "\n",
    "* How can we ascertain the quality on similar, out-of-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a (general) model\n",
    "\n",
    "* Given a quadratic process, a linear model has high bias.\n",
    "* \"Connecting-the-dots\" will fail to generalize (high variance).\n",
    "* Balance model complexity with complexity of DGP.\n",
    "\n",
    "![overfit](imgs/under-over-fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: predicting survival on the Titanic with Decision Trees\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Did a given passenger survive the Titanic distaster?\n",
    "* The (simple) tree below has mediocre accuracy\n",
    "\n",
    "<img src=\"imgs/image_6.png\" width=\"50%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reducing Bias with more complicated models\n",
    "\n",
    "* Improve performance by \"growing\" the decision tree model.\n",
    "* Decrease the number of passengers required in leaf nodes.\n",
    "* Effect: \"Learn\" individual passengers?\n",
    "* How do the know your model generalizes?\n",
    "\n",
    "<img src=\"imgs/Titanic_Decision_Tree.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train-Test Split\n",
    "\n",
    "To assess your model for overfitting to the data, randomly split the data into a \"training set\" and a \"test set\".\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* The training set is used to fit the model (train the predictor).\n",
    "* The test set is used to test the goodness-of-fit of the fit model.\n",
    "* *similar* to bootstrap estimating a regression model.\n",
    "\n",
    "<img src=\"imgs/train_test.jpg\">\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The machine learning training pipeline:\n",
    "\n",
    "<img src=\"imgs/train-test.png\" width=\"50%\">\n",
    "\n",
    "Scikit-Learn has functions that help us do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Scikit-Learn for train-test split\n",
    "\n",
    "* Splitting a dataset using `sklearn.model_selection.train_test_split` \n",
    "* Given features `X` and a target array `y`,\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "```\n",
    "randomly splits the features and target into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tips.drop('tip', axis=1)\n",
    "y = tips.tip\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(X_train)/len(X),\n",
    "    len(X_test)/len(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Prediction Pipeline\n",
    "\n",
    "* Train a simple linear regression model on the tips data\n",
    "* Split the data into a training and test set:\n",
    "    - fit the model on the training set\n",
    "    - compute the error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips.drop(['tip', 'sex', 'smoker', 'day', 'time' ], axis=1)\n",
    "y = tips.tip\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "pl = Pipeline([\n",
    "   ('lin-reg', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "preds = pl.predict(X_test)\n",
    "rmse = np.sqrt(np.mean((preds - y_test)**2))\n",
    "print (\"RMSE: %s\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: evaluating model fit\n",
    "\n",
    "* Complex models are required to model complex phenomena.\n",
    "* How can you tell a complex model isn't over-fitting to the data?\n",
    "    - Answer: split into a training set and a test set."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
